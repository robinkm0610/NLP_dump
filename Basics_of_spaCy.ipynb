{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2udneX7uO1Mmre4J/Zc3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robinkm0610/NLP_dump/blob/main/Basics_of_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basics of Spacy"
      ],
      "metadata": {
        "id": "fci0uYIk1DtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A-2aMh1afpMo"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download('en_core_web_sm')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9E2wfUb1q8m",
        "outputId": "427883c7-36f7-474d-c3e6-02f86d3508dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "9Fvh6t7C1n27"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading a Text Document\n",
        "doc1=nlp(\"We are learning spaCy\")\n",
        "doc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1nEG7VU1NSl",
        "outputId": "191708c8-f387-452c-ab0b-ae56488753ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "We are learning spaCy"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = \"\"\"\n",
        "\n",
        "Hello Guys,\n",
        "\n",
        "We are learning spaCy , a cool nlp library.\n",
        "\n",
        "Some of its Features are:-\n",
        "\n",
        "Easy deep learning integration.\n",
        "Non-destructive tokenization.\n",
        "Export to numpy data arrays.\n",
        "Named entity recognition.\n",
        "Support for 51+ languages.\n",
        "Pre-trained word vectors.\n",
        "State-of-the-art speed.\n",
        "Part-of-speech tagging.\n",
        "Robust, rigorously evaluated accuracy and many more\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-13LH_4E2hdo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization\n"
      ],
      "metadata": {
        "id": "b9LZYvW_C_bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = nlp(file1)"
      ],
      "metadata": {
        "id": "tiazJuJ0DFly"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num,sentence in enumerate(file1.sents):\n",
        "    print(f'{num}:{sentence}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlayDyLzC9I3",
        "outputId": "160ee033-d15c-4e73-e875-e601869a320a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\n",
            "\n",
            "Hello Guys,\n",
            "\n",
            "We are learning spaCy , a cool nlp library.\n",
            "\n",
            "\n",
            "1:Some of its Features are:-\n",
            "\n",
            "Easy deep learning integration.\n",
            "\n",
            "2:Non-destructive tokenization.\n",
            "\n",
            "3:Export to numpy data arrays.\n",
            "\n",
            "4:Named entity recognition.\n",
            "\n",
            "5:Support for 51+ languages.\n",
            "\n",
            "6:Pre-trained word vectors.\n",
            "\n",
            "7:State-of-the-art speed.\n",
            "\n",
            "8:Part-of-speech tagging.\n",
            "\n",
            "9:Robust, rigorously evaluated accuracy and many more\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Tokenization\n"
      ],
      "metadata": {
        "id": "Tr9TxBrfDM_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"We are learning spaCy\"\n",
        "doc1 = nlp(doc1)"
      ],
      "metadata": {
        "id": "L8g6G9CzDEXb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for token in doc1:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X35L6d6vDS6T",
        "outputId": "bce95a78-d79b-480c-ea3f-4e9d03156450"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We\n",
            "are\n",
            "learning\n",
            "spaCy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For getting list of words, use split() method\n",
        "doc1.text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGTVyvwhDX1m",
        "outputId": "fcf833e5-0dd1-4353-8e69-a4a965872b29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'are', 'learning', 'spaCy']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Properties\n"
      ],
      "metadata": {
        "id": "HsXP2k9ODljl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc2=nlp(\"I have 3 coins and a 10 rupee note\")\n",
        "doc2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKHW_KuzDnX5",
        "outputId": "a4df9929-0d30-4e78-d1cd-6a55ce85a1b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "I have 3 coins and a 10 rupee note"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc2:\n",
        "  print(word.text, word.is_alpha, word.is_digit, word.is_currency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7eNplHjDiw_",
        "outputId": "b82ada0b-6a80-4085-fdcc-5bf40d45f9e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I True False False\n",
            "have True False False\n",
            "3 False True False\n",
            "coins True False False\n",
            "and True False False\n",
            "a True False False\n",
            "10 False True False\n",
            "rupee True False False\n",
            "note True False False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## is_stop property\n",
        "for word in doc2:\n",
        "  print(word.text, word.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVtLZq2VDxDr",
        "outputId": "aeed461e-3cec-42d1-c551-c5b5c4f767c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I True\n",
            "have True\n",
            "3 False\n",
            "coins False\n",
            "and True\n",
            "a True\n",
            "10 False\n",
            "rupee False\n",
            "note False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## shape property\n",
        "for word in doc1:\n",
        "  print(word.text, word.shape_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTD1YGOwD9K5",
        "outputId": "02ace5fe-a31e-4a9b-a0df-941e5a9140e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We Xx\n",
            "are xxx\n",
            "learning xxxx\n",
            "spaCy xxxXx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part of speech Tagging\n"
      ],
      "metadata": {
        "id": "ZlZXoHfhEKhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## .pos_ property\n",
        "for word in doc1:\n",
        "  print(word.text, word.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rty3dt4EEGjH",
        "outputId": "c29bc8f9-a16e-4b5b-d4c5-4f3a21c97891"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We PRON\n",
            "are AUX\n",
            "learning VERB\n",
            "spaCy VERB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## .tag_ property\n",
        "for word in doc1:\n",
        "    print(word.text,word.pos_,word.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw9-R6YLEROH",
        "outputId": "9e02da21-0ebc-427c-b54b-f347a5a7887b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We PRON PRP\n",
            "are AUX VBP\n",
            "learning VERB VBG\n",
            "spaCy VERB VBN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## meaning of pos abbrev.\n",
        "spacy.explain('NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "szRa6S47Gvw-",
        "outputId": "c81084e9-4f1a-470c-ef37-d58dfc425835"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'noun, singular or mass'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spacy.explain('VBP')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tmyBgsGbGzUo",
        "outputId": "1931a49c-22c3-4068-98ea-ce154ed09b26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'verb, non-3rd person singular present'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual dependency using displacy\n"
      ],
      "metadata": {
        "id": "N_XjQ5XhG38d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n"
      ],
      "metadata": {
        "id": "hLX7XAaVG1sz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc1,style='dep', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "xvVoqhKBG56Y",
        "outputId": "f676f54c-ebe8-4061-f004-3f81aad5d023"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"7be59485b4ab484b80f3db89824fc8be-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">We</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">are</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">spaCy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7be59485b4ab484b80f3db89824fc8be-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7be59485b4ab484b80f3db89824fc8be-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7be59485b4ab484b80f3db89824fc8be-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7be59485b4ab484b80f3db89824fc8be-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-7be59485b4ab484b80f3db89824fc8be-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-7be59485b4ab484b80f3db89824fc8be-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "xWqC9IeskBt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc3=nlp(\"playing played player\")\n"
      ],
      "metadata": {
        "id": "hfaZgBfMjxQp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc3:\n",
        "  print(word.text, word.lemma_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VUzxU8CkGIe",
        "outputId": "26de568b-8ddb-432d-971a-c453d5331bd5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing play\n",
            "played play\n",
            "player player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc4=nlp(\"walks walk walked\")\n"
      ],
      "metadata": {
        "id": "Pm1Lz0f2kSKp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc4:\n",
        "  print(word.text, word.lemma_, word.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksEo_doRkU3o",
        "outputId": "c2ca50f6-a1ac-4be1-f0ad-39dffde52976"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "walks walk NOUN\n",
            "walk walk NOUN\n",
            "walked walk VERB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Entity Recognition or Detection\n"
      ],
      "metadata": {
        "id": "8GbOCopqkcdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc5=nlp(\"By 2025 , India will grow so much in Technical field and earn more than 5 million dollars\")\n"
      ],
      "metadata": {
        "id": "64cdI0cskamF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in doc5.ents:\n",
        "  print(word.text, word.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFjtKvxckeBE",
        "outputId": "5c630083-aa9c-471b-ff6a-07fb98314016"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025 DATE\n",
            "India GPE\n",
            "Technical GPE\n",
            "more than 5 million dollars MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('GPE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "duG25I85kkDE",
        "outputId": "a0b9be67-e839-450b-83b9-afd431bb1eb5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc5,style='ent',jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "AZA4s51Dkq3g",
        "outputId": "1d75f8d6-c1a3-47cf-c870-d8fccfdaaf44"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " will grow so much in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Technical\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " field and earn \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    more than 5 million dollars\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Similarity\n"
      ],
      "metadata": {
        "id": "pE1YXEGFk0R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word1=nlp(\"dog\")\n",
        "word2=nlp(\"cat\")"
      ],
      "metadata": {
        "id": "mSKVA-lzkuMV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word1.similarity(word2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmdSQjkMk3qj",
        "outputId": "8a2b1cd8-2c24-48ed-de6f-fe096d81051b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-c15fd92115da>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  word1.similarity(word2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6847176149951816"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5=nlp(\"cat dog bird fish\")\n"
      ],
      "metadata": {
        "id": "W5PJtlSklAs6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## similarity between words in a sentence\n",
        "\n",
        "for w1 in doc5:\n",
        "    for w2 in doc5:\n",
        "        print((w1.text,w2.text),\"Similarly :-\",w1.similarity(w2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5nyg7M9lFZ1",
        "outputId": "a0a08caf-1965-4bec-e436-4fa990209a37"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('cat', 'cat') Similarly :- 1.0\n",
            "('cat', 'dog') Similarly :- 0.6201360821723938\n",
            "('cat', 'bird') Similarly :- 0.6236063241958618\n",
            "('cat', 'fish') Similarly :- 0.14771202206611633\n",
            "('dog', 'cat') Similarly :- 0.6201360821723938\n",
            "('dog', 'dog') Similarly :- 1.0\n",
            "('dog', 'bird') Similarly :- 0.6349874138832092\n",
            "('dog', 'fish') Similarly :- 0.4316307306289673\n",
            "('bird', 'cat') Similarly :- 0.6236063241958618\n",
            "('bird', 'dog') Similarly :- 0.6349874138832092\n",
            "('bird', 'bird') Similarly :- 1.0\n",
            "('bird', 'fish') Similarly :- 0.320694237947464\n",
            "('fish', 'cat') Similarly :- 0.14771202206611633\n",
            "('fish', 'dog') Similarly :- 0.4316307306289673\n",
            "('fish', 'bird') Similarly :- 0.320694237947464\n",
            "('fish', 'fish') Similarly :- 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-9944edaf9c94>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print((w1.text,w2.text),\"Similarly :-\",w1.similarity(w2))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords\n"
      ],
      "metadata": {
        "id": "wO2qBkVzpDGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "metadata": {
        "id": "ImZmpteapAIR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(STOP_WORDS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjcMa0h7pHRu",
        "outputId": "4003cfef-6912-4a7f-adb9-e5466d3a7453"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'just', 'herein', 'because', 'noone', 'nowhere', 'thence', 'alone', 'therefore', 'there', 'again', 'see', 'will', 'with', 'might', 'seems', 'used', 'thereupon', '‘ve', 'done', 'seemed', '’m', 'into', 'regarding', 'everything', 'after', 'enough', 'unless', 'so', 'where', 'several', 'doing', 'before', 'those', '‘ll', 'well', '’s', 'serious', 'do', 'one', 'cannot', 'than', 'using', 'others', 'somewhere', 'below', 'whenever', 'otherwise', 'whoever', 'move', 'via', 'itself', 'whole', 'five', 'beyond', \"'ve\", 'either', 'seeming', 'it', 'were', \"'s\", 'twelve', 'in', 'under', 'these', 'n‘t', 'thereafter', 'therein', 'meanwhile', 'four', 'not', 'everyone', 'now', 'further', 'on', 'or', 'third', 'whence', '’ve', 'last', 'would', 'was', 'thus', 'we', 'upon', 'almost', 'onto', 'becoming', 'its', 'hereafter', 'any', 'anything', 'among', 'formerly', 'how', 'whose', 'back', 'may', 'nobody', 'this', 'eleven', 'became', 'nor', 'becomes', 'neither', 'most', 'besides', 'own', 'along', 'did', 'two', 'none', 'hereby', 'both', 'mine', 'his', 'former', 'whatever', 'something', 'always', 'an', 'whither', 'ten', 'hereupon', 'though', '’ll', 'anyway', 'they', 'even', 'quite', 'me', '‘m', 'why', 'ca', 'whereas', 'often', 'to', 'somehow', 'rather', 'throughout', 'yourselves', 'does', 'our', 'beforehand', 'namely', 'towards', 'wherein', 'please', 'and', 'front', \"'d\", 'fifty', 'six', 'latterly', 'forty', 'sometime', 'their', 'had', 'call', 'my', 'around', 'must', 'without', 'amongst', 'across', 'been', '‘s', 'get', 'behind', 'during', 'thereby', 'over', 'take', 'nine', 'side', 'when', 'have', 'n’t', 'that', 'indeed', 'become', 'here', 'toward', 'he', 'other', 'eight', 'thru', 'empty', 're', 'sixty', 'first', 'if', 'beside', 'hers', 'be', 'moreover', \"'m\", '‘d', 'few', \"n't\", 'whereupon', 'wherever', 'what', 'each', 'while', 'yet', 'myself', 'anyone', 'but', 'has', 'fifteen', 'although', 'a', 'then', 'make', 'put', 'us', 'for', 'should', 'such', 'elsewhere', 'perhaps', 'yours', 'many', 'until', '’re', 'against', 'more', 'also', 'him', 'amount', 'less', 'off', 'being', 'except', 'hundred', 'hence', 'no', 'up', 'at', 'about', 'already', 'full', 'say', 'latter', 'anywhere', 'else', 'three', \"'re\", 'every', 'whom', 'next', 'i', 'ever', 'could', 'her', 'am', 'everywhere', 'twenty', 'ourselves', 'another', 'very', 'never', 'mostly', 'as', 'least', 'seem', 'per', 'top', 'whereby', 'various', 'however', 'sometimes', '‘re', 'only', 'down', 'whereafter', 'give', 'nothing', '’d', 'out', 'bottom', 'made', 'who', 'she', 'too', 'through', 'since', 'really', 'above', 'your', 'the', 'still', 'whether', 'between', 'is', 'yourself', 'you', 'nevertheless', \"'ll\", 'are', 'them', 'within', 'of', 'once', 'show', 'someone', 'due', 'all', 'herself', 'together', 'same', 'themselves', 'from', 'much', 'keep', 'anyhow', 'can', 'part', 'some', 'by', 'go', 'himself', 'which', 'name', 'ours', 'afterwards'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORDS.add('ohh')\n",
        "nlp.vocab['ohh'].is_stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENJIjmbzpLMN",
        "outputId": "7c6d2e67-8e73-4257-9028-ce089863bedd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noun Chunks"
      ],
      "metadata": {
        "id": "8sTA-AP3pc1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc15=nlp('the man playing football is a great player.')\n"
      ],
      "metadata": {
        "id": "w_kX_bbDpaUj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in doc15.noun_chunks:\n",
        "  print(w.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxbHDcW8pfaM",
        "outputId": "ce9d36bd-7613-484d-e3bb-a9e3c195a320"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the man\n",
            "football\n",
            "a great player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## get root words\n",
        "\n",
        "for w in doc15.noun_chunks:\n",
        "  print(w.root.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FzDHFtRqFsq",
        "outputId": "f4f9e577-c2b7-4ccc-b5da-a75bd6380469"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man\n",
            "football\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in doc15.noun_chunks:\n",
        "  print(w.root.text, \"--connected by =\", w.root.head.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhqast82qRlr",
        "outputId": "5f49ca54-ee0d-4238-a465-bf602495a617"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man --connected by = is\n",
            "football --connected by = playing\n",
            "player --connected by = is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Segmentation and Boundary Detection"
      ],
      "metadata": {
        "id": "nwzcIR2GqvpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc25=nlp(\"Hello friends ,we are learning spaCy. Are you all enjoying? keep learning\")\n"
      ],
      "metadata": {
        "id": "FtSwFd7MqmmP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc25.sents:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffXDY9XRqxw2",
        "outputId": "7fd47b45-5ca7-4fcb-d24f-bab8ff4fab4e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello friends ,we are learning spaCy.\n",
            "Are you all enjoying?\n",
            "keep learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3=nlp(\"spaCy is an amazing library\\nWe want to learn it in depth\\nThat's why we are here :P\")\n"
      ],
      "metadata": {
        "id": "-pDITPr3q0DO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in doc3.sents:\n",
        "    print(s.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b_4sHP3q3gy",
        "outputId": "784a5251-4be7-4c01-a922-4305e00e2492"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy is an amazing library\n",
            "We want to learn it in depth\n",
            "That's why we are here :P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37Hwa9oErB56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}